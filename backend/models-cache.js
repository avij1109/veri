// Top 50 AI Models Cache with comprehensive metadata
// This replaces the previous simple cache with detailed model information

export const TOP_50_MODELS = {
  // Large Language Models (Chat/General) - 20 models
  'gpt-4': {
    id: 'gpt-4',
    name: 'GPT-4',
    provider: 'OpenAI',
    category: 'chat',
    parameters: '1.76T',
    accuracy: 0.92,
    cost_per_1k_tokens: 0.03,
    speed_tokens_per_sec: 50,
    use_cases: ['chat', 'reasoning', 'creative writing', 'code assistance'],
    strengths: ['Superior reasoning', 'Multimodal capabilities', 'Following complex instructions'],
    weaknesses: ['Expensive', 'Slower inference', 'Rate limited'],
    best_for: 'Complex reasoning and high-quality responses',
    evaluatedAt: '2024-09-10',
    tags: ['premium', 'reasoning', 'multimodal']
  },
  'gpt-3.5-turbo': {
    id: 'gpt-3.5-turbo',
    name: 'GPT-3.5 Turbo',
    provider: 'OpenAI',
    category: 'chat',
    parameters: '175B',
    accuracy: 0.85,
    cost_per_1k_tokens: 0.001,
    speed_tokens_per_sec: 150,
    use_cases: ['chat', 'content generation', 'simple coding', 'summarization'],
    strengths: ['Fast', 'Cost-effective', 'Good general performance'],
    weaknesses: ['Less capable than GPT-4', 'Limited reasoning'],
    best_for: 'High-volume applications requiring good quality at low cost',
    evaluatedAt: '2024-09-08',
    tags: ['fast', 'cost-effective', 'popular']
  },
  'claude-3-opus': {
    id: 'claude-3-opus',
    name: 'Claude-3 Opus',
    provider: 'Anthropic',
    category: 'chat',
    parameters: '400B',
    accuracy: 0.91,
    cost_per_1k_tokens: 0.015,
    speed_tokens_per_sec: 80,
    use_cases: ['complex reasoning', 'analysis', 'creative writing', 'research'],
    strengths: ['Excellent reasoning', 'Safe outputs', 'Long context'],
    weaknesses: ['Expensive', 'Conservative responses'],
    best_for: 'Complex analysis and reasoning tasks',
    evaluatedAt: '2024-09-09',
    tags: ['reasoning', 'safe', 'long-context']
  },
  'claude-3-sonnet': {
    id: 'claude-3-sonnet',
    name: 'Claude-3 Sonnet',
    provider: 'Anthropic',
    category: 'chat',
    parameters: '200B',
    accuracy: 0.87,
    cost_per_1k_tokens: 0.003,
    speed_tokens_per_sec: 120,
    use_cases: ['balanced tasks', 'content creation', 'analysis', 'coding'],
    strengths: ['Balanced performance/cost', 'Good reasoning', 'Fast'],
    weaknesses: ['Not as capable as Opus', 'Conservative'],
    best_for: 'Balanced performance and cost requirements',
    evaluatedAt: '2024-09-09',
    tags: ['balanced', 'fast', 'reasoning']
  },
  'claude-3-haiku': {
    id: 'claude-3-haiku',
    name: 'Claude-3 Haiku',
    provider: 'Anthropic',
    category: 'chat',
    parameters: '20B',
    accuracy: 0.82,
    cost_per_1k_tokens: 0.00025,
    speed_tokens_per_sec: 200,
    use_cases: ['simple tasks', 'content moderation', 'classification', 'quick responses'],
    strengths: ['Very fast', 'Extremely cost-effective', 'Good for simple tasks'],
    weaknesses: ['Limited capabilities', 'Less reasoning'],
    best_for: 'High-volume simple tasks requiring speed',
    evaluatedAt: '2024-09-09',
    tags: ['fast', 'cheap', 'simple']
  },
  'llama-2-7b-chat': {
    id: 'llama-2-7b-chat',
    name: 'Llama-2 7B Chat',
    provider: 'Meta',
    category: 'chat',
    parameters: '7B',
    accuracy: 0.78,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 300,
    use_cases: ['open-source chat', 'fine-tuning', 'local deployment'],
    strengths: ['Open source', 'Fast', 'Can run locally'],
    weaknesses: ['Lower accuracy', 'Requires technical setup'],
    best_for: 'Open-source projects and local deployment',
    evaluatedAt: '2024-09-05',
    tags: ['open-source', 'local', 'fast']
  },
  'llama-2-13b-chat': {
    id: 'llama-2-13b-chat',
    name: 'Llama-2 13B Chat',
    provider: 'Meta',
    category: 'chat',
    parameters: '13B',
    accuracy: 0.82,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 200,
    use_cases: ['open-source chat', 'balanced performance', 'research'],
    strengths: ['Good balance', 'Open source', 'Better than 7B'],
    weaknesses: ['Larger memory requirements', 'Still needs setup'],
    best_for: 'Balanced open-source applications',
    evaluatedAt: '2024-09-05',
    tags: ['open-source', 'balanced', 'research']
  },
  'llama-2-70b-chat': {
    id: 'llama-2-70b-chat',
    name: 'Llama-2 70B Chat',
    provider: 'Meta',
    category: 'chat',
    parameters: '70B',
    accuracy: 0.86,
    cost_per_1k_tokens: 0.0007,
    speed_tokens_per_sec: 80,
    use_cases: ['high-quality open-source', 'research', 'complex tasks'],
    strengths: ['High quality', 'Open source', 'Competitive with commercial'],
    weaknesses: ['Large memory requirements', 'Slower'],
    best_for: 'High-quality open-source applications',
    evaluatedAt: '2024-09-05',
    tags: ['open-source', 'high-quality', 'large']
  },
  'llama-3-8b-instruct': {
    id: 'llama-3-8b-instruct',
    name: 'Llama-3 8B Instruct',
    provider: 'Meta',
    category: 'chat',
    parameters: '8B',
    accuracy: 0.81,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 280,
    use_cases: ['latest open-source', 'instruction following', 'fine-tuning'],
    strengths: ['Latest model', 'Good instruction following', 'Fast'],
    weaknesses: ['Still developing ecosystem', 'Limited compared to larger models'],
    best_for: 'Latest open-source instruction-following tasks',
    evaluatedAt: '2024-09-01',
    tags: ['latest', 'open-source', 'instructions']
  },
  'llama-3-70b-instruct': {
    id: 'llama-3-70b-instruct',
    name: 'Llama-3 70B Instruct',
    provider: 'Meta',
    category: 'chat',
    parameters: '70B',
    accuracy: 0.88,
    cost_per_1k_tokens: 0.0007,
    speed_tokens_per_sec: 70,
    use_cases: ['high-quality open-source', 'complex instructions', 'research'],
    strengths: ['Latest technology', 'Excellent instruction following', 'High quality'],
    weaknesses: ['Large resource requirements', 'Newer model'],
    best_for: 'Latest high-quality open-source applications',
    evaluatedAt: '2024-09-01',
    tags: ['latest', 'high-quality', 'instructions']
  },
  'mistral-7b-instruct': {
    id: 'mistral-7b-instruct',
    name: 'Mistral-7B Instruct',
    provider: 'Mistral AI',
    category: 'chat',
    parameters: '7B',
    accuracy: 0.79,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 320,
    use_cases: ['efficient chat', 'European alternative', 'fine-tuning'],
    strengths: ['Very efficient', 'Good performance/size ratio', 'European'],
    weaknesses: ['Smaller capacity', 'Less known'],
    best_for: 'Efficient applications with good performance',
    evaluatedAt: '2024-09-07',
    tags: ['efficient', 'european', 'performance']
  },
  'mixtral-8x7b-instruct': {
    id: 'mixtral-8x7b-instruct',
    name: 'Mixtral-8x7B Instruct',
    provider: 'Mistral AI',
    category: 'chat',
    parameters: '47B',
    accuracy: 0.85,
    cost_per_1k_tokens: 0.0005,
    speed_tokens_per_sec: 150,
    use_cases: ['mixture of experts', 'multilingual', 'efficient large model'],
    strengths: ['Mixture of experts efficiency', 'Good performance', 'Multilingual'],
    weaknesses: ['Complex architecture', 'Newer model'],
    best_for: 'Efficient large-scale applications',
    evaluatedAt: '2024-09-07',
    tags: ['mixture-of-experts', 'multilingual', 'efficient']
  },
  'gemma-2b-it': {
    id: 'gemma-2b-it',
    name: 'Gemma-2B IT',
    provider: 'Google',
    category: 'chat',
    parameters: '2B',
    accuracy: 0.75,
    cost_per_1k_tokens: 0.0001,
    speed_tokens_per_sec: 400,
    use_cases: ['lightweight chat', 'mobile deployment', 'edge computing'],
    strengths: ['Very small', 'Fast', 'Can run on mobile'],
    weaknesses: ['Limited capabilities', 'Basic responses'],
    best_for: 'Edge deployment and mobile applications',
    evaluatedAt: '2024-09-06',
    tags: ['lightweight', 'mobile', 'edge']
  },
  'gemma-7b-it': {
    id: 'gemma-7b-it',
    name: 'Gemma-7B IT',
    provider: 'Google',
    category: 'chat',
    parameters: '7B',
    accuracy: 0.80,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 250,
    use_cases: ['Google ecosystem', 'instruction tuning', 'research'],
    strengths: ['Google technology', 'Well-trained', 'Good performance'],
    weaknesses: ['Less ecosystem', 'Newer'],
    best_for: 'Google ecosystem applications',
    evaluatedAt: '2024-09-06',
    tags: ['google', 'research', 'instructions']
  },
  'vicuna-7b': {
    id: 'vicuna-7b',
    name: 'Vicuna-7B',
    provider: 'LMSYS',
    category: 'chat',
    parameters: '7B',
    accuracy: 0.77,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 300,
    use_cases: ['research', 'chatbot research', 'open-source chat'],
    strengths: ['Research quality', 'Open source', 'Good chat abilities'],
    weaknesses: ['Research focus', 'Less commercial support'],
    best_for: 'Research and academic applications',
    evaluatedAt: '2024-09-04',
    tags: ['research', 'academic', 'open-source']
  },
  'vicuna-13b': {
    id: 'vicuna-13b',
    name: 'Vicuna-13B',
    provider: 'LMSYS',
    category: 'chat',
    parameters: '13B',
    accuracy: 0.81,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 180,
    use_cases: ['research', 'academic studies', 'chat evaluation'],
    strengths: ['Better than 7B', 'Research quality', 'Well-evaluated'],
    weaknesses: ['Academic focus', 'Less commercial'],
    best_for: 'Academic research and evaluation',
    evaluatedAt: '2024-09-04',
    tags: ['research', 'academic', 'evaluation']
  },
  'alpaca-7b': {
    id: 'alpaca-7b',
    name: 'Alpaca-7B',
    provider: 'Stanford',
    category: 'chat',
    parameters: '7B',
    accuracy: 0.76,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 290,
    use_cases: ['instruction following', 'research', 'education'],
    strengths: ['Good instruction following', 'Educational', 'Research quality'],
    weaknesses: ['Limited training data', 'Academic focus'],
    best_for: 'Educational and research instruction following',
    evaluatedAt: '2024-09-03',
    tags: ['education', 'instructions', 'stanford']
  },
  'chatglm3-6b': {
    id: 'chatglm3-6b',
    name: 'ChatGLM3-6B',
    provider: 'Tsinghua',
    category: 'chat',
    parameters: '6B',
    accuracy: 0.74,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 320,
    use_cases: ['bilingual chat', 'Chinese language', 'academic research'],
    strengths: ['Bilingual capabilities', 'Chinese expertise', 'Academic quality'],
    weaknesses: ['Smaller size', 'Academic focus'],
    best_for: 'Bilingual and Chinese language applications',
    evaluatedAt: '2024-09-02',
    tags: ['bilingual', 'chinese', 'academic']
  },
  'qwen-7b-chat': {
    id: 'qwen-7b-chat',
    name: 'Qwen-7B Chat',
    provider: 'Alibaba',
    category: 'chat',
    parameters: '7B',
    accuracy: 0.78,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 280,
    use_cases: ['Chinese applications', 'e-commerce', 'multilingual'],
    strengths: ['Strong Chinese capabilities', 'Commercial backing', 'Multilingual'],
    weaknesses: ['Focus on Chinese market', 'Less global adoption'],
    best_for: 'Chinese and Asian market applications',
    evaluatedAt: '2024-09-01',
    tags: ['chinese', 'commercial', 'multilingual']
  },
  'yi-34b-chat': {
    id: 'yi-34b-chat',
    name: 'Yi-34B Chat',
    provider: '01.AI',
    category: 'chat',
    parameters: '34B',
    accuracy: 0.84,
    cost_per_1k_tokens: 0.0005,
    speed_tokens_per_sec: 100,
    use_cases: ['large open-source', 'multilingual', 'complex tasks'],
    strengths: ['Large open-source model', 'Good performance', 'Multilingual'],
    weaknesses: ['Large resource requirements', 'Newer model'],
    best_for: 'Large-scale open-source applications',
    evaluatedAt: '2024-08-30',
    tags: ['large', 'open-source', 'multilingual']
  },

  // Code Generation Models - 10 models
  'codellama-7b-instruct': {
    id: 'codellama-7b-instruct',
    name: 'CodeLlama-7B Instruct',
    provider: 'Meta',
    category: 'code',
    parameters: '7B',
    accuracy: 0.82,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 300,
    use_cases: ['code generation', 'code completion', 'programming assistance'],
    strengths: ['Specialized for code', 'Fast', 'Good for simple tasks'],
    weaknesses: ['Limited to simpler code', 'Smaller context'],
    best_for: 'Fast code completion and simple generation',
    evaluatedAt: '2024-09-08',
    tags: ['code', 'fast', 'completion']
  },
  'codellama-13b-instruct': {
    id: 'codellama-13b-instruct',
    name: 'CodeLlama-13B Instruct',
    provider: 'Meta',
    category: 'code',
    parameters: '13B',
    accuracy: 0.85,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 200,
    use_cases: ['complex code generation', 'debugging', 'code explanation'],
    strengths: ['Better code quality', 'Good explanations', 'Balanced performance'],
    weaknesses: ['Slower than 7B', 'More resources'],
    best_for: 'Balanced code generation and explanation',
    evaluatedAt: '2024-09-08',
    tags: ['code', 'balanced', 'explanation']
  },
  'codellama-34b-instruct': {
    id: 'codellama-34b-instruct',
    name: 'CodeLlama-34B Instruct',
    provider: 'Meta',
    category: 'code',
    parameters: '34B',
    accuracy: 0.88,
    cost_per_1k_tokens: 0.0005,
    speed_tokens_per_sec: 80,
    use_cases: ['complex programming', 'architecture design', 'code review'],
    strengths: ['High-quality code', 'Complex reasoning', 'Best CodeLlama'],
    weaknesses: ['Slow', 'Resource intensive', 'Expensive'],
    best_for: 'High-quality complex code generation',
    evaluatedAt: '2024-09-08',
    tags: ['code', 'complex', 'high-quality']
  },
  'starcoder': {
    id: 'starcoder',
    name: 'StarCoder',
    provider: 'Hugging Face',
    category: 'code',
    parameters: '15B',
    accuracy: 0.83,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 180,
    use_cases: ['open-source coding', 'multiple languages', 'code completion'],
    strengths: ['Multiple programming languages', 'Open source', 'Good performance'],
    weaknesses: ['Less specialized than CodeLlama', 'Academic focus'],
    best_for: 'Multi-language open-source code generation',
    evaluatedAt: '2024-09-07',
    tags: ['open-source', 'multi-language', 'code']
  },
  'starcoder2-15b': {
    id: 'starcoder2-15b',
    name: 'StarCoder2-15B',
    provider: 'Hugging Face',
    category: 'code',
    parameters: '15B',
    accuracy: 0.85,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 170,
    use_cases: ['updated code generation', 'research', 'open-source projects'],
    strengths: ['Updated model', 'Better than StarCoder', 'Open source'],
    weaknesses: ['Newer model', 'Less adoption', 'Research focus'],
    best_for: 'Latest open-source code generation',
    evaluatedAt: '2024-09-06',
    tags: ['updated', 'open-source', 'research']
  },
  'deepseek-coder-6.7b': {
    id: 'deepseek-coder-6.7b',
    name: 'DeepSeek-Coder-6.7B',
    provider: 'DeepSeek',
    category: 'code',
    parameters: '6.7B',
    accuracy: 0.81,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 320,
    use_cases: ['efficient coding', 'fast completion', 'lightweight deployment'],
    strengths: ['Fast', 'Efficient', 'Good performance/size'],
    weaknesses: ['Smaller capacity', 'Less complex reasoning'],
    best_for: 'Fast, efficient code completion',
    evaluatedAt: '2024-09-05',
    tags: ['efficient', 'fast', 'lightweight']
  },
  'deepseek-v3.1': {
    id: 'deepseek-v3.1',
    name: 'DeepSeek v3.1',
    provider: 'DeepSeek',
    category: 'language',
    parameters: '671B',
    accuracy: 0.88,
    cost_per_1k_tokens: 0.001,
    speed_tokens_per_sec: 120,
    use_cases: ['text generation', 'conversation', 'reasoning', 'creative writing'],
    strengths: ['Large scale', 'Strong reasoning', 'Versatile language model'],
    weaknesses: ['High computational cost', 'Slower inference'],
    best_for: 'Complex language tasks and reasoning',
    evaluatedAt: '2024-12-20',
    tags: ['llm', 'language', 'reasoning', 'latest']
  },
  'phind-codellama-34b': {
    id: 'phind-codellama-34b',
    name: 'Phind-CodeLlama-34B',
    provider: 'Phind',
    category: 'code',
    parameters: '34B',
    accuracy: 0.89,
    cost_per_1k_tokens: 0.0005,
    speed_tokens_per_sec: 90,
    use_cases: ['optimized coding', 'search-aware coding', 'complex problems'],
    strengths: ['Optimized for coding', 'Search integration', 'High quality'],
    weaknesses: ['Expensive', 'Slower', 'Commercial focus'],
    best_for: 'Search-integrated high-quality coding',
    evaluatedAt: '2024-09-04',
    tags: ['optimized', 'search', 'high-quality']
  },
  'wizardcoder-15b': {
    id: 'wizardcoder-15b',
    name: 'WizardCoder-15B',
    provider: 'Microsoft',
    category: 'code',
    parameters: '15B',
    accuracy: 0.84,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 160,
    use_cases: ['enterprise coding', 'complex logic', 'code review'],
    strengths: ['Enterprise quality', 'Good reasoning', 'Microsoft backing'],
    weaknesses: ['Commercial model', 'Less open', 'Enterprise focus'],
    best_for: 'Enterprise code generation and review',
    evaluatedAt: '2024-09-03',
    tags: ['enterprise', 'microsoft', 'reasoning']
  },
  'codet5-plus': {
    id: 'codet5-plus',
    name: 'CodeT5+',
    provider: 'Salesforce',
    category: 'code',
    parameters: '16B',
    accuracy: 0.83,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 170,
    use_cases: ['code understanding', 'summarization', 'translation'],
    strengths: ['Code understanding', 'Good summarization', 'Research quality'],
    weaknesses: ['Academic focus', 'Less generation', 'Complex setup'],
    best_for: 'Code understanding and summarization',
    evaluatedAt: '2024-09-02',
    tags: ['understanding', 'summarization', 'research']
  },
  'incoder-6b': {
    id: 'incoder-6b',
    name: 'InCoder-6B',
    provider: 'Facebook',
    category: 'code',
    parameters: '6B',
    accuracy: 0.80,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 330,
    use_cases: ['code infilling', 'completion', 'lightweight coding'],
    strengths: ['Code infilling', 'Fast', 'Lightweight'],
    weaknesses: ['Specialized use', 'Smaller capacity', 'Facebook focus'],
    best_for: 'Code infilling and completion tasks',
    evaluatedAt: '2024-09-01',
    tags: ['infilling', 'completion', 'lightweight']
  },

  // Multimodal Models - 8 models
  'gpt-4-vision': {
    id: 'gpt-4-vision',
    name: 'GPT-4 Vision',
    provider: 'OpenAI',
    category: 'multimodal',
    parameters: '1.76T',
    accuracy: 0.91,
    cost_per_1k_tokens: 0.04,
    speed_tokens_per_sec: 40,
    use_cases: ['image analysis', 'visual reasoning', 'document processing'],
    strengths: ['Best vision capabilities', 'Complex reasoning', 'High accuracy'],
    weaknesses: ['Very expensive', 'Slow', 'Limited availability'],
    best_for: 'High-quality image analysis and reasoning',
    evaluatedAt: '2024-09-10',
    tags: ['vision', 'premium', 'reasoning']
  },
  'claude-3-opus-vision': {
    id: 'claude-3-opus-vision',
    name: 'Claude-3 Opus Vision',
    provider: 'Anthropic',
    category: 'multimodal',
    parameters: '400B',
    accuracy: 0.89,
    cost_per_1k_tokens: 0.018,
    speed_tokens_per_sec: 60,
    use_cases: ['document analysis', 'image understanding', 'visual reasoning'],
    strengths: ['Good vision capabilities', 'Safe outputs', 'Document processing'],
    weaknesses: ['Expensive', 'Conservative', 'Limited availability'],
    best_for: 'Safe and accurate document analysis',
    evaluatedAt: '2024-09-09',
    tags: ['vision', 'safe', 'documents']
  },
  'llava-1.5-7b': {
    id: 'llava-1.5-7b',
    name: 'LLaVA-1.5-7B',
    provider: 'Community',
    category: 'multimodal',
    parameters: '7B',
    accuracy: 0.78,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 200,
    use_cases: ['open-source vision', 'image chatbot', 'research'],
    strengths: ['Open source', 'Good performance', 'Research friendly'],
    weaknesses: ['Lower accuracy', 'Setup complexity', 'Academic focus'],
    best_for: 'Open-source vision-language applications',
    evaluatedAt: '2024-09-07',
    tags: ['open-source', 'vision', 'research']
  },
  'llava-1.5-13b': {
    id: 'llava-1.5-13b',
    name: 'LLaVA-1.5-13B',
    provider: 'Community',
    category: 'multimodal',
    parameters: '13B',
    accuracy: 0.82,
    cost_per_1k_tokens: 0.0004,
    speed_tokens_per_sec: 150,
    use_cases: ['better open-source vision', 'complex image analysis', 'research'],
    strengths: ['Better than 7B', 'Open source', 'Good reasoning'],
    weaknesses: ['Larger resources', 'Complex setup', 'Academic'],
    best_for: 'Higher-quality open-source vision tasks',
    evaluatedAt: '2024-09-07',
    tags: ['open-source', 'vision', 'improved']
  },
  'blip-2': {
    id: 'blip-2',
    name: 'BLIP-2',
    provider: 'Salesforce',
    category: 'multimodal',
    parameters: '12B',
    accuracy: 0.79,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 180,
    use_cases: ['image captioning', 'visual QA', 'image understanding'],
    strengths: ['Good captioning', 'Fast', 'Specialized'],
    weaknesses: ['Limited to specific tasks', 'Less general', 'Academic'],
    best_for: 'Image captioning and visual question answering',
    evaluatedAt: '2024-09-06',
    tags: ['captioning', 'specialized', 'qa']
  },
  'instructblip': {
    id: 'instructblip',
    name: 'InstructBLIP',
    provider: 'Salesforce',
    category: 'multimodal',
    parameters: '14B',
    accuracy: 0.81,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 170,
    use_cases: ['instruction-based vision', 'complex visual tasks', 'research'],
    strengths: ['Instruction following', 'Better than BLIP-2', 'Research quality'],
    weaknesses: ['Academic focus', 'Complex setup', 'Limited adoption'],
    best_for: 'Instruction-based visual understanding',
    evaluatedAt: '2024-09-05',
    tags: ['instructions', 'vision', 'research']
  },
  'minigpt-4': {
    id: 'minigpt-4',
    name: 'MiniGPT-4',
    provider: 'Community',
    category: 'multimodal',
    parameters: '13B',
    accuracy: 0.76,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 190,
    use_cases: ['lightweight multimodal', 'demo applications', 'research'],
    strengths: ['Lightweight', 'Easy to use', 'Good demos'],
    weaknesses: ['Lower accuracy', 'Limited capabilities', 'Demo quality'],
    best_for: 'Lightweight multimodal demonstrations',
    evaluatedAt: '2024-09-04',
    tags: ['lightweight', 'demo', 'easy']
  },
  'flamingo': {
    id: 'flamingo',
    name: 'Flamingo',
    provider: 'DeepMind',
    category: 'multimodal',
    parameters: '80B',
    accuracy: 0.85,
    cost_per_1k_tokens: 0.0008,
    speed_tokens_per_sec: 100,
    use_cases: ['few-shot learning', 'research', 'vision understanding'],
    strengths: ['Few-shot capabilities', 'Research quality', 'DeepMind technology'],
    weaknesses: ['Research model', 'Limited availability', 'Academic focus'],
    best_for: 'Research in few-shot vision-language learning',
    evaluatedAt: '2024-09-03',
    tags: ['few-shot', 'research', 'deepmind']
  },

  // Specialized Models - 12 models
  'whisper-large-v3': {
    id: 'whisper-large-v3',
    name: 'Whisper-Large-v3',
    provider: 'OpenAI',
    category: 'speech',
    parameters: '1550M',
    accuracy: 0.95,
    cost_per_1k_tokens: 0.006,
    speed_tokens_per_sec: 100,
    use_cases: ['speech recognition', 'transcription', 'multilingual audio'],
    strengths: ['Excellent accuracy', 'Multilingual', 'Robust'],
    weaknesses: ['Large model', 'Slower', 'Audio only'],
    best_for: 'High-quality speech transcription',
    evaluatedAt: '2024-09-10',
    tags: ['speech', 'transcription', 'multilingual']
  },
  'whisper-medium': {
    id: 'whisper-medium',
    name: 'Whisper-Medium',
    provider: 'OpenAI',
    category: 'speech',
    parameters: '769M',
    accuracy: 0.92,
    cost_per_1k_tokens: 0.004,
    speed_tokens_per_sec: 150,
    use_cases: ['balanced transcription', 'real-time audio', 'applications'],
    strengths: ['Good balance', 'Faster than large', 'Still accurate'],
    weaknesses: ['Less accurate than large', 'Audio only'],
    best_for: 'Balanced speed and accuracy transcription',
    evaluatedAt: '2024-09-10',
    tags: ['speech', 'balanced', 'real-time']
  },
  'clip-vit-l-14': {
    id: 'clip-vit-l-14',
    name: 'CLIP-ViT-L/14',
    provider: 'OpenAI',
    category: 'vision-text',
    parameters: '428M',
    accuracy: 0.87,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 500,
    use_cases: ['image-text matching', 'search', 'classification'],
    strengths: ['Fast', 'Versatile', 'Good embeddings'],
    weaknesses: ['Not generative', 'Limited to classification', 'Older'],
    best_for: 'Image-text similarity and classification',
    evaluatedAt: '2024-09-08',
    tags: ['embeddings', 'classification', 'fast']
  },
  'sentence-bert': {
    id: 'sentence-bert',
    name: 'Sentence-BERT',
    provider: 'Community',
    category: 'embeddings',
    parameters: '110M',
    accuracy: 0.84,
    cost_per_1k_tokens: 0.0001,
    speed_tokens_per_sec: 1000,
    use_cases: ['text embeddings', 'similarity', 'search'],
    strengths: ['Fast embeddings', 'Good similarity', 'Lightweight'],
    weaknesses: ['Embeddings only', 'Not generative', 'Older'],
    best_for: 'Text similarity and embedding tasks',
    evaluatedAt: '2024-09-07',
    tags: ['embeddings', 'similarity', 'fast']
  },
  'e5-large': {
    id: 'e5-large',
    name: 'E5-Large',
    provider: 'Microsoft',
    category: 'embeddings',
    parameters: '355M',
    accuracy: 0.86,
    cost_per_1k_tokens: 0.0001,
    speed_tokens_per_sec: 800,
    use_cases: ['text embeddings', 'retrieval', 'enterprise search'],
    strengths: ['High-quality embeddings', 'Enterprise ready', 'Fast'],
    weaknesses: ['Embeddings only', 'Microsoft ecosystem', 'Specialized'],
    best_for: 'Enterprise text embedding and retrieval',
    evaluatedAt: '2024-09-06',
    tags: ['embeddings', 'enterprise', 'retrieval']
  },
  'bge-large-en': {
    id: 'bge-large-en',
    name: 'BGE-Large-EN',
    provider: 'BAAI',
    category: 'embeddings',
    parameters: '355M',
    accuracy: 0.85,
    cost_per_1k_tokens: 0.0001,
    speed_tokens_per_sec: 750,
    use_cases: ['English embeddings', 'retrieval', 'search'],
    strengths: ['Excellent English embeddings', 'Fast', 'Open source'],
    weaknesses: ['English only', 'Embeddings only', 'Academic'],
    best_for: 'High-quality English text embeddings',
    evaluatedAt: '2024-09-05',
    tags: ['embeddings', 'english', 'open-source']
  },
  't5-large': {
    id: 't5-large',
    name: 'T5-Large',
    provider: 'Google',
    category: 'text-to-text',
    parameters: '770M',
    accuracy: 0.83,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 400,
    use_cases: ['text-to-text', 'summarization', 'translation'],
    strengths: ['Versatile', 'Good performance', 'Google technology'],
    weaknesses: ['Older architecture', 'Less capable than new models'],
    best_for: 'General text-to-text transformation tasks',
    evaluatedAt: '2024-09-04',
    tags: ['text-to-text', 'versatile', 'google']
  },
  'flan-t5-xl': {
    id: 'flan-t5-xl',
    name: 'FLAN-T5-XL',
    provider: 'Google',
    category: 'text-to-text',
    parameters: '3B',
    accuracy: 0.85,
    cost_per_1k_tokens: 0.0003,
    speed_tokens_per_sec: 300,
    use_cases: ['instruction following', 'text tasks', 'fine-tuning'],
    strengths: ['Good instruction following', 'Versatile', 'Open source'],
    weaknesses: ['Older architecture', 'Less conversational'],
    best_for: 'Instruction-following text generation',
    evaluatedAt: '2024-09-03',
    tags: ['instructions', 'versatile', 'open-source']
  },
  'mt5-large': {
    id: 'mt5-large',
    name: 'mT5-Large',
    provider: 'Google',
    category: 'multilingual',
    parameters: '1.2B',
    accuracy: 0.81,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 350,
    use_cases: ['multilingual tasks', 'translation', 'cross-lingual'],
    strengths: ['Multilingual', 'Good for translation', 'Open source'],
    weaknesses: ['Older architecture', 'Less capable per language'],
    best_for: 'Multilingual and translation tasks',
    evaluatedAt: '2024-09-02',
    tags: ['multilingual', 'translation', 'cross-lingual']
  },
  'bart-large': {
    id: 'bart-large',
    name: 'BART-Large',
    provider: 'Facebook',
    category: 'summarization',
    parameters: '400M',
    accuracy: 0.82,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 450,
    use_cases: ['summarization', 'text generation', 'denoising'],
    strengths: ['Good summarization', 'Fast', 'Specialized'],
    weaknesses: ['Older model', 'Limited scope', 'Not conversational'],
    best_for: 'Text summarization and denoising',
    evaluatedAt: '2024-09-01',
    tags: ['summarization', 'denoising', 'specialized']
  },
  'pegasus-large': {
    id: 'pegasus-large',
    name: 'Pegasus-Large',
    provider: 'Google',
    category: 'summarization',
    parameters: '568M',
    accuracy: 0.84,
    cost_per_1k_tokens: 0.0002,
    speed_tokens_per_sec: 400,
    use_cases: ['document summarization', 'news summarization', 'abstractive'],
    strengths: ['Excellent summarization', 'Specialized', 'Google technology'],
    weaknesses: ['Summarization only', 'Older model', 'Limited scope'],
    best_for: 'High-quality document summarization',
    evaluatedAt: '2024-08-31',
    tags: ['summarization', 'documents', 'specialized']
  },
  'distilbert': {
    id: 'distilbert',
    name: 'DistilBERT',
    provider: 'Hugging Face',
    category: 'classification',
    parameters: '66M',
    accuracy: 0.79,
    cost_per_1k_tokens: 0.0001,
    speed_tokens_per_sec: 1200,
    use_cases: ['text classification', 'lightweight NLP', 'edge deployment'],
    strengths: ['Very fast', 'Lightweight', 'Good for classification'],
    weaknesses: ['Limited capabilities', 'Classification only', 'Older'],
    best_for: 'Fast text classification and edge deployment',
    evaluatedAt: '2024-08-30',
    tags: ['classification', 'lightweight', 'fast']
  }
};

// Category mappings for easy filtering
export const MODEL_CATEGORIES = {
  chat: Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'chat'),
  code: Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'code'),
  multimodal: Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'multimodal'),
  speech: Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'speech'),
  'vision-text': Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'vision-text'),
  embeddings: Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'embeddings'),
  'text-to-text': Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'text-to-text'),
  multilingual: Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'multilingual'),
  summarization: Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'summarization'),
  classification: Object.keys(TOP_50_MODELS).filter(id => TOP_50_MODELS[id].category === 'classification')
};

// Helper functions for the cache
export function getModelById(modelId) {
  return TOP_50_MODELS[modelId] || null;
}

export function getModelsByCategory(category) {
  return MODEL_CATEGORIES[category]?.map(id => TOP_50_MODELS[id]) || [];
}

export function searchModels(query, category = null) {
  const models = category ? getModelsByCategory(category) : Object.values(TOP_50_MODELS);
  const searchTerms = query.toLowerCase().split(' ');
  
  return models.filter(model => {
    const searchableText = `${model.name} ${model.provider} ${model.use_cases.join(' ')} ${model.tags.join(' ')} ${model.best_for}`.toLowerCase();
    return searchTerms.every(term => searchableText.includes(term));
  });
}

export function getTopModelsByAccuracy(limit = 10, category = null) {
  const models = category ? getModelsByCategory(category) : Object.values(TOP_50_MODELS);
  return models
    .sort((a, b) => b.accuracy - a.accuracy)
    .slice(0, limit);
}

export function getModelRecommendations(useCase, budget = null, speed = null) {
  let models = Object.values(TOP_50_MODELS);
  
  // Filter by use case
  models = models.filter(model => 
    model.use_cases.some(uc => uc.toLowerCase().includes(useCase.toLowerCase())) ||
    model.best_for.toLowerCase().includes(useCase.toLowerCase())
  );
  
  // Filter by budget (cost per 1k tokens)
  if (budget) {
    models = models.filter(model => model.cost_per_1k_tokens <= budget);
  }
  
  // Filter by speed requirement
  if (speed) {
    models = models.filter(model => model.speed_tokens_per_sec >= speed);
  }
  
  // Sort by accuracy
  return models.sort((a, b) => b.accuracy - a.accuracy);
}